{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f765a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/workspace/VLM_Embed/src/model/vlm_backbone/internvideo2/modeling_internvideo2.py:541: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "[2026-01-01 12:07:48,211] DEBUG [matplotlib:342] matplotlib data path: /workspace/VLM_Embed/vlm/lib/python3.12/site-packages/matplotlib/mpl-data\n",
      "[2026-01-01 12:07:48,217] DEBUG [matplotlib:342] CONFIGDIR=/root/.config/matplotlib\n",
      "[2026-01-01 12:07:48,238] DEBUG [matplotlib:1560] interactive is False\n",
      "[2026-01-01 12:07:48,239] DEBUG [matplotlib:1561] platform is linux\n",
      "[2026-01-01 12:07:48,258] DEBUG [matplotlib:342] CACHEDIR=/root/.cache/matplotlib\n",
      "[2026-01-01 12:07:48,260] DEBUG [matplotlib.font_manager:1635] Using fontManager instance from /root/.cache/matplotlib/fontlist-v390.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusedMLP of flash_attn is not installed!!!\n",
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n",
      "flash_attn_interface or bert_padding of flash_attn is not installed!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-01 12:07:48,424] DEBUG [matplotlib.pyplot:496] Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "[2026-01-01 12:07:48,427] DEBUG [matplotlib.pyplot:496] Loaded backend inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from src.arguments import ModelArguments, DataArguments\n",
    "from src.model.model import MMEBModel\n",
    "from src.model.processor import load_processor, QWEN2_VL, VLM_IMAGE_TOKENS, \\\n",
    "    Qwen2_VL_process_fn, LLAVA_QWEN2, FastVLM_process_fn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.image_transforms import (\n",
    "    convert_to_rgb,\n",
    "    resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d924ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-01 12:12:33,194] INFO [src.utils:21] Loading processor from: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor load here for LLAVA-QWEN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-01 12:12:33,487] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:33,508] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:33,788] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/apple/FastVLM-0.5B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2026-01-01 12:12:34,489] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:34,506] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:34,776] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:34,793] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:35,099] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:35,116] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:35,121] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n",
      "[2026-01-01 12:12:35,122] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-01 12:12:35,396] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:35,412] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:35,686] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:35,704] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:36,007] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:36,025] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:36,302] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:36,319] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:36,956] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "[2026-01-01 12:12:36,975] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/generation_config.json HTTP/1.1\" 200 0\n",
      "[2026-01-01 12:12:37,254] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base model from HF: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMEBModel(\n",
       "  (encoder): LlavaQwen2ForCausalLM(\n",
       "    (model): LlavaQwen2Model(\n",
       "      (embed_tokens): Embedding(151936, 896)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      (vision_tower): MobileCLIPVisionTower(\n",
       "        (vision_tower): MCi(\n",
       "          (model): FastViT(\n",
       "            (patch_embed): Sequential(\n",
       "              (0): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              )\n",
       "              (1): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
       "              )\n",
       "              (2): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (network): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (1): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(96, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (4): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (5): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (6): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (7): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (8): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (9): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (10): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (11): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (3): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(192, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=192)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (4): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (4): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (5): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (6): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (7): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (8): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (9): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (10): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (11): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (12): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (13): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (14): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (15): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (16): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (17): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (18): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (19): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (20): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (21): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (22): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (23): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (5): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(384, 768, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=384)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (6): RepCPE(\n",
       "                (reparam_conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "              )\n",
       "              (7): Sequential(\n",
       "                (0): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (8): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(768, 1536, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=768)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (9): RepCPE(\n",
       "                (reparam_conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "              )\n",
       "              (10): Sequential(\n",
       "                (0): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
       "                      (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
       "                      (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (conv_exp): MobileOneBlock(\n",
       "              (se): SEBlock(\n",
       "                (reduce): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (expand): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (activation): GELU(approximate='none')\n",
       "              (reparam_conv): Conv2d(1536, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)\n",
       "            )\n",
       "            (head): GlobalPool2D()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mm_projector): Sequential(\n",
       "        (0): Linear(in_features=3072, out_features=896, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=896, out_features=896, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "  )\n",
       "  (cross_entropy): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_args = ModelArguments(\n",
    "#     model_name='Qwen/Qwen2-VL-2B',\n",
    "#     checkpoint_path='TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
    "#     pooling='last',\n",
    "#     normalize=True,\n",
    "#     model_backbone='qwen2_vl',\n",
    "#     lora=True\n",
    "# )\n",
    "model_args = ModelArguments(\n",
    "    model_name='apple/FastVLM-0.5B',\n",
    "    pooling='last',\n",
    "    normalize=True,\n",
    "    model_backbone=LLAVA_QWEN2,\n",
    ")\n",
    "data_args = DataArguments()\n",
    "\n",
    "processor = load_processor(model_args, None)\n",
    "model = MMEBModel.load(model_args)\n",
    "model = model.to('cuda', dtype=torch.bfloat16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e449f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<image>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.image_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629ef9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2VLConfig {\n",
       "  \"architectures\": [\n",
       "    \"Qwen2VLForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"dtype\": \"bfloat16\",\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 1536,\n",
       "  \"image_token_id\": 151655,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8960,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 28,\n",
       "  \"model_type\": \"qwen2_vl\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": {\n",
       "    \"mrope_section\": [\n",
       "      16,\n",
       "      24,\n",
       "      24\n",
       "    ],\n",
       "    \"rope_type\": \"default\",\n",
       "    \"type\": \"default\"\n",
       "  },\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": 32768,\n",
       "  \"text_config\": {\n",
       "    \"architectures\": [\n",
       "      \"Qwen2VLForConditionalGeneration\"\n",
       "    ],\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bos_token_id\": 151643,\n",
       "    \"dtype\": \"bfloat16\",\n",
       "    \"eos_token_id\": 151645,\n",
       "    \"hidden_act\": \"silu\",\n",
       "    \"hidden_size\": 1536,\n",
       "    \"image_token_id\": null,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 8960,\n",
       "    \"layer_types\": [\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\",\n",
       "      \"full_attention\"\n",
       "    ],\n",
       "    \"max_position_embeddings\": 32768,\n",
       "    \"max_window_layers\": 28,\n",
       "    \"model_type\": \"qwen2_vl_text\",\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_hidden_layers\": 28,\n",
       "    \"num_key_value_heads\": 2,\n",
       "    \"rms_norm_eps\": 1e-06,\n",
       "    \"rope_scaling\": {\n",
       "      \"mrope_section\": [\n",
       "        16,\n",
       "        24,\n",
       "        24\n",
       "      ],\n",
       "      \"rope_type\": \"default\",\n",
       "      \"type\": \"default\"\n",
       "    },\n",
       "    \"rope_theta\": 1000000.0,\n",
       "    \"sliding_window\": null,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"use_cache\": true,\n",
       "    \"use_sliding_window\": false,\n",
       "    \"video_token_id\": null,\n",
       "    \"vision_end_token_id\": 151653,\n",
       "    \"vision_start_token_id\": 151652,\n",
       "    \"vision_token_id\": 151654,\n",
       "    \"vocab_size\": 151936\n",
       "  },\n",
       "  \"transformers_version\": \"4.56.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"video_token_id\": 151656,\n",
       "  \"vision_config\": {\n",
       "    \"depth\": 32,\n",
       "    \"dtype\": \"bfloat16\",\n",
       "    \"embed_dim\": 1280,\n",
       "    \"hidden_act\": \"quick_gelu\",\n",
       "    \"hidden_size\": 1536,\n",
       "    \"in_channels\": 3,\n",
       "    \"in_chans\": 3,\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"mlp_ratio\": 4,\n",
       "    \"model_type\": \"qwen2_vl\",\n",
       "    \"num_heads\": 16,\n",
       "    \"patch_size\": 14,\n",
       "    \"spatial_merge_size\": 2,\n",
       "    \"spatial_patch_size\": 14,\n",
       "    \"temporal_patch_size\": 2\n",
       "  },\n",
       "  \"vision_end_token_id\": 151653,\n",
       "  \"vision_start_token_id\": 151652,\n",
       "  \"vision_token_id\": 151654,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ecddd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_tower = model.encoder.get_vision_tower()\n",
    "vision_tower.config['image_cfg']['patch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11ed4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (3072x12x12). Calculated output size: (3072x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m768\u001b[39m, \u001b[32m768\u001b[39m).to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, dtype=torch.bfloat16)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     y = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m y.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:75\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tune_vision_tower:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:88\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward_images\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     86\u001b[39m         image_features.append(image_feature)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     image_forward_outs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_image_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     image_features = \u001b[38;5;28mself\u001b[39m.feature_select(image_forward_outs).to(images.dtype)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip/__init__.py:57\u001b[39m, in \u001b[36mMCi.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Any, *args, **kwargs) -> Any:\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A forward function of the model.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1446\u001b[39m, in \u001b[36mFastViT.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m x = \u001b[38;5;28mself\u001b[39m.forward_tokens(x)\n\u001b[32m   1445\u001b[39m \u001b[38;5;66;03m# for image classification/embedding\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m cls_out = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m   1449\u001b[39m out_dict = \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:232\u001b[39m, in \u001b[36mMobileOneBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Inference mode forward pass.\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_mode:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreparam_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Multi-branched train-time forward pass.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Skip branch output\u001b[39;00m\n\u001b[32m    236\u001b[39m identity_out = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:111\u001b[39m, in \u001b[36mSEBlock.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    109\u001b[39m b, c, h, w = inputs.size()\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# x = F.avg_pool2d(inputs, kernel_size=[h, w])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m x = \u001b[38;5;28mself\u001b[39m.reduce(x)\n\u001b[32m    113\u001b[39m x = F.relu(x)\n",
      "\u001b[31mRuntimeError\u001b[39m: Given input size: (3072x12x12). Calculated output size: (3072x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 768, 768).to('cuda', dtype=torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    y = model.encoder.get_vision_tower()(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b91a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
