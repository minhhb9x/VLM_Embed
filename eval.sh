python  eval_mmeb.py  --model_name llava-hf/llava-onevision-qwen2-0.5b-ov-hf --encode_output_path  ./MMEB-evaloutputs/llava-0.5B_v1/  --pooling  eos  --normalize  True  --bf16  --dataset_name  TIGER-Lab/MMEB-eval  --subset_name  HatefulMemes --dataset_split  test  --per_device_eval_batch_size  4  --image_dir  eval_images/ 
# python  eval_mmeb.py  --model_name raghavlite/B3_Qwen2_2B --encode_output_path  ./MMEB-evaloutputs/B2_Qwen2_2B/  --pooling  eos  --normalize  True  --lora  --lora_r  8  --bf16  --dataset_name  TIGER-Lab/MMEB-eval  --subset_name  HatefulMemes  --dataset_split  test  --per_device_eval_batch_size  4  --image_dir  eval_images/  --tgt_prefix_mod
# rm -rf ./MMEB-evaloutputs/B2_Qwen2_2B_v0/