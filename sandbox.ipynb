{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f765a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/workspace/VLM_Embed/src/model/vlm_backbone/internvideo2/modeling_internvideo2.py:541: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "[2026-01-02 12:56:08,608] DEBUG [matplotlib:342] matplotlib data path: /workspace/VLM_Embed/vlm/lib/python3.12/site-packages/matplotlib/mpl-data\n",
      "[2026-01-02 12:56:08,614] DEBUG [matplotlib:342] CONFIGDIR=/root/.config/matplotlib\n",
      "[2026-01-02 12:56:08,624] DEBUG [matplotlib:1560] interactive is False\n",
      "[2026-01-02 12:56:08,625] DEBUG [matplotlib:1561] platform is linux\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusedMLP of flash_attn is not installed!!!\n",
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n",
      "flash_attn_interface or bert_padding of flash_attn is not installed!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-02 12:56:08,646] DEBUG [matplotlib:342] CACHEDIR=/root/.cache/matplotlib\n",
      "[2026-01-02 12:56:08,648] DEBUG [matplotlib.font_manager:1635] Using fontManager instance from /root/.cache/matplotlib/fontlist-v390.json\n",
      "[2026-01-02 12:56:08,833] DEBUG [matplotlib.pyplot:496] Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "[2026-01-02 12:56:08,835] DEBUG [matplotlib.pyplot:496] Loaded backend inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from src.arguments import ModelArguments, DataArguments\n",
    "from src.model.model import MMEBModel\n",
    "from src.model.processor import load_processor, QWEN2_VL, VLM_IMAGE_TOKENS, \\\n",
    "    Qwen2_VL_process_fn, LLAVA_QWEN2, FastVLM_process_fn\n",
    "from src.utils import batch_to_device\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.image_transforms import (\n",
    "    convert_to_rgb,\n",
    "    resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d924ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-02 12:56:11,574] INFO [src.utils:21] Loading processor from: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor load here for LLAVA-QWEN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-02 12:56:11,604] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): huggingface.co:443\n",
      "[2026-01-02 12:56:13,105] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2026-01-02 12:56:13,327] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2026-01-02 12:56:13,749] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/apple/FastVLM-0.5B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2026-01-02 12:56:14,660] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-02 12:56:14,875] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-02 12:56:16,029] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2026-01-02 12:56:16,226] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "/workspace/.hf_home/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1458: UserWarning: Overwriting fastvithd in registry with transformers_modules.apple.FastVLM-0.5B.16375720c2d673fa583e57e9876afde27549c7d0.llava_qwen.fastvithd. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "[2026-01-02 12:56:16,673] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2026-01-02 12:56:16,893] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2026-01-02 12:56:16,902] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-02 13:02:57,465] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2026-01-02 13:02:59,395] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "[2026-01-02 13:02:59,644] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/generation_config.json HTTP/1.1\" 200 0\n",
      "[2026-01-02 13:03:00,055] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMEBModel(\n",
       "  (encoder): LlavaQwen2ForCausalLM(\n",
       "    (model): LlavaQwen2Model(\n",
       "      (embed_tokens): Embedding(151936, 896)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "      (vision_tower): MobileCLIPVisionTower(\n",
       "        (vision_tower): MCi(\n",
       "          (model): FastViT(\n",
       "            (patch_embed): Sequential(\n",
       "              (0): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              )\n",
       "              (1): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
       "              )\n",
       "              (2): MobileOneBlock(\n",
       "                (se): Identity()\n",
       "                (activation): GELU(approximate='none')\n",
       "                (reparam_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "            )\n",
       "            (network): ModuleList(\n",
       "              (0): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
       "                      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (1): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(96, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (2): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (4): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (5): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (6): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (7): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (8): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (9): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (10): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (11): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
       "                      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (3): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(192, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=192)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (4): Sequential(\n",
       "                (0): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (4): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (5): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (6): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (7): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (8): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (9): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (10): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (11): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (12): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (13): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (14): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (15): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (16): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (17): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (18): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (19): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (20): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (21): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (22): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (23): RepMixerBlock(\n",
       "                  (token_mixer): RepMixer(\n",
       "                    (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
       "                      (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (5): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(384, 768, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=384)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (6): RepCPE(\n",
       "                (reparam_conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "              )\n",
       "              (7): Sequential(\n",
       "                (0): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (2): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (3): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
       "                      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (8): PatchEmbed(\n",
       "                (proj): Sequential(\n",
       "                  (0): ReparamLargeKernelConv(\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (se): Identity()\n",
       "                    (lkb_reparam): Conv2d(768, 1536, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=768)\n",
       "                  )\n",
       "                  (1): MobileOneBlock(\n",
       "                    (se): Identity()\n",
       "                    (activation): GELU(approximate='none')\n",
       "                    (reparam_conv): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (9): RepCPE(\n",
       "                (reparam_conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "              )\n",
       "              (10): Sequential(\n",
       "                (0): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
       "                      (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (1): AttentionBlock(\n",
       "                  (norm): LayerNormChannel()\n",
       "                  (token_mixer): MHSA(\n",
       "                    (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "                    (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                    (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                    (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (convffn): ConvFFN(\n",
       "                    (conv): Sequential(\n",
       "                      (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
       "                      (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (drop): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (conv_exp): MobileOneBlock(\n",
       "              (se): SEBlock(\n",
       "                (reduce): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (expand): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              )\n",
       "              (activation): GELU(approximate='none')\n",
       "              (reparam_conv): Conv2d(1536, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)\n",
       "            )\n",
       "            (head): GlobalPool2D()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mm_projector): Sequential(\n",
       "        (0): Linear(in_features=3072, out_features=896, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=896, out_features=896, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "  )\n",
       "  (cross_entropy): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_args = ModelArguments(\n",
    "#     model_name='Qwen/Qwen2-VL-2B',\n",
    "#     checkpoint_path='TIGER-Lab/VLM2Vec-Qwen2VL-2B',\n",
    "#     pooling='last',\n",
    "#     normalize=True,\n",
    "#     model_backbone='qwen2_vl',\n",
    "#     lora=True\n",
    "# )\n",
    "model_args = ModelArguments(\n",
    "    model_name='apple/FastVLM-0.5B',\n",
    "    pooling='last',\n",
    "    normalize=True,\n",
    "    model_backbone=LLAVA_QWEN2,\n",
    ")\n",
    "data_args = DataArguments()\n",
    "\n",
    "processor = load_processor(model_args, None)\n",
    "model = MMEBModel.build(model_args)\n",
    "model = model.to('cuda', dtype=torch.bfloat16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629ef9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2048, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor_inputs = {\n",
    "    \"text\": [f'{VLM_IMAGE_TOKENS[LLAVA_QWEN2]} Represent the given image with the following question: What is in the image',\n",
    "          f'{VLM_IMAGE_TOKENS[LLAVA_QWEN2]} Represent the given image with the following question: What is in the image'],\n",
    "    \"images\": [Image.open('example.jpg').resize((500, 1000)),\n",
    "            Image.open('example.jpg')],\n",
    "}\n",
    "\n",
    "inputs = FastVLM_process_fn(\n",
    "    processor_inputs,\n",
    "    processor, \n",
    "    # square_padding=True\n",
    "    )\n",
    "inputs = batch_to_device(inputs, \"cuda\")\n",
    "inputs['images'][0].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecddd5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/model.py:134\u001b[39m, in \u001b[36mMMEBModel.encode_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pooled_output, image_features, attention_matrix, output_hidden_states\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel_backbone\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m [LLAVA_QWEN2, QWEN2_VL]:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# print(\"Encoding input for FastVLM model backbone\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(hidden_states, \u001b[33m'\u001b[39m\u001b[33mbatch_image_embeds\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    136\u001b[39m         image_features = hidden_states.batch_image_embeds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/language_model/llava_qwen.py:99\u001b[39m, in \u001b[36mLlavaQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, images, image_sizes, return_dict, cache_position)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     73\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     86\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m# print(\"Preparing inputs for multimodal forward pass.\")\u001b[39;00m\n\u001b[32m     90\u001b[39m         \u001b[38;5;66;03m# print(f\"Batch size of input_ids: {input_ids.shape[0]}\")\u001b[39;00m\n\u001b[32m     91\u001b[39m         (\n\u001b[32m     92\u001b[39m             input_ids,\n\u001b[32m     93\u001b[39m             position_ids,\n\u001b[32m     94\u001b[39m             attention_mask,\n\u001b[32m     95\u001b[39m             past_key_values,\n\u001b[32m     96\u001b[39m             inputs_embeds,\n\u001b[32m     97\u001b[39m             labels,\n\u001b[32m     98\u001b[39m             image_features\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_inputs_labels_for_multimodal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_sizes\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     output = \u001b[38;5;28msuper\u001b[39m().forward(\n\u001b[32m    110\u001b[39m         input_ids=input_ids,\n\u001b[32m    111\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m         return_dict=return_dict\n\u001b[32m    120\u001b[39m     )\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m LlavaQwen2OutputWithPast(\n\u001b[32m    122\u001b[39m         loss=output.loss,\n\u001b[32m    123\u001b[39m         logits=output.logits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m         batch_image_embeds=image_features\n\u001b[32m    128\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/llava_arch.py:175\u001b[39m, in \u001b[36mLlavaMetaForCausalLM.prepare_inputs_labels_for_multimodal\u001b[39m\u001b[34m(self, input_ids, position_ids, attention_mask, past_key_values, labels, images, image_sizes)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    174\u001b[39m     concat_images = [image[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m image.ndim == \u001b[32m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m image \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m image_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m split_sizes = [image.shape[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(image_features) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/llava_arch.py:142\u001b[39m, in \u001b[36mLlavaMetaForCausalLM.encode_images\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_images\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     image_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(image_features) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m    144\u001b[39m         image_features = [image_feature.to(dtype=torch.bfloat16) \u001b[38;5;28;01mfor\u001b[39;00m image_feature \u001b[38;5;129;01min\u001b[39;00m image_features]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:75\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tune_vision_tower:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:84\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward_images\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     82\u001b[39m image_features = []\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     image_forward_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_image_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     image_feature = \u001b[38;5;28mself\u001b[39m.feature_select(image_forward_out).to(image.dtype)\n\u001b[32m     86\u001b[39m     image_features.append(image_feature)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip/__init__.py:57\u001b[39m, in \u001b[36mMCi.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Any, *args, **kwargs) -> Any:\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A forward function of the model.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.hf_home/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1446\u001b[39m, in \u001b[36mFastViT.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m x = \u001b[38;5;28mself\u001b[39m.forward_tokens(x)\n\u001b[32m   1445\u001b[39m \u001b[38;5;66;03m# for image classification/embedding\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m cls_out = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m   1449\u001b[39m out_dict = \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.hf_home/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:232\u001b[39m, in \u001b[36mMobileOneBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Inference mode forward pass.\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_mode:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreparam_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Multi-branched train-time forward pass.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Skip branch output\u001b[39;00m\n\u001b[32m    236\u001b[39m identity_out = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/.hf_home/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:115\u001b[39m, in \u001b[36mSEBlock.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    113\u001b[39m x = F.relu(x)\n\u001b[32m    114\u001b[39m x = \u001b[38;5;28mself\u001b[39m.expand(x)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m x = \u001b[43mtorch\u001b[49m.sigmoid(x)\n\u001b[32m    116\u001b[39m x = x.view(-\u001b[32m1\u001b[39m, c, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inputs * x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1481\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1602\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1961\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.encode_input(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11ed4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (3072x12x12). Calculated output size: (3072x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m768\u001b[39m, \u001b[32m768\u001b[39m).to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, dtype=torch.bfloat16)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     y = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m y.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:75\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tune_vision_tower:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip_encoder.py:88\u001b[39m, in \u001b[36mMobileCLIPVisionTower.forward_images\u001b[39m\u001b[34m(self, images)\u001b[39m\n\u001b[32m     86\u001b[39m         image_features.append(image_feature)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     image_forward_outs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_image_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     image_features = \u001b[38;5;28mself\u001b[39m.feature_select(image_forward_outs).to(images.dtype)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/src/model/llava/model/multimodal_encoder/mobileclip/__init__.py:57\u001b[39m, in \u001b[36mMCi.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Any, *args, **kwargs) -> Any:\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"A forward function of the model.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1446\u001b[39m, in \u001b[36mFastViT.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m x = \u001b[38;5;28mself\u001b[39m.forward_tokens(x)\n\u001b[32m   1445\u001b[39m \u001b[38;5;66;03m# for image classification/embedding\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m cls_out = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m   1449\u001b[39m out_dict = \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:232\u001b[39m, in \u001b[36mMobileOneBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Inference mode forward pass.\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_mode:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreparam_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Multi-branched train-time forward pass.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Skip branch output\u001b[39;00m\n\u001b[32m    236\u001b[39m identity_out = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1780\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1778\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/VLM_Embed/vlm/lib/python3.11/site-packages/torch/nn/modules/module.py:1791\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1789\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1790\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1794\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:111\u001b[39m, in \u001b[36mSEBlock.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    109\u001b[39m b, c, h, w = inputs.size()\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# x = F.avg_pool2d(inputs, kernel_size=[h, w])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m x = \u001b[38;5;28mself\u001b[39m.reduce(x)\n\u001b[32m    113\u001b[39m x = F.relu(x)\n",
      "\u001b[31mRuntimeError\u001b[39m: Given input size: (3072x12x12). Calculated output size: (3072x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 768, 768).to('cuda', dtype=torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    y = model.encoder.get_vision_tower()(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b91a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
